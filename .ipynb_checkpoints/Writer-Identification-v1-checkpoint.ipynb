{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f18843a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install opencv-python\n",
    "# !pip install matplotlib\n",
    "# !pip install tensorflow\n",
    "# !pip install scikit-learn\n",
    "# !pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0947775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18192\\774798532.py:12: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "159a41da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to your handwriting dataset\n",
    "dataset_dir = 'Resized-Datasets'\n",
    "\n",
    "# Load the dataset\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Assuming each subdirectory in the dataset directory corresponds to a different writer\n",
    "for writer_dir in os.listdir(dataset_dir):\n",
    "    writer_images = []\n",
    "    writer_labels = []\n",
    "    writer_path = os.path.join(dataset_dir, writer_dir)\n",
    "#     print(\"writer_path: \", writer_path)\n",
    "    \n",
    "    # Assuming each image file in the writer directory corresponds to a handwriting sample\n",
    "    for image_file in os.listdir(writer_path):\n",
    "        image_path = os.path.join(writer_path, image_file)\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "#         img = cv2.resize(img, (28, 28))\n",
    "        writer_images.append(img)\n",
    "        writer_labels.append(int(writer_dir))  # Assuming the writer directory is named with a numerical label\n",
    "#         writer_labels.append(writer_dir)\n",
    "    \n",
    "    # images += writer_images\n",
    "    images.extend(writer_images)\n",
    "    labels.extend(writer_labels)\n",
    "\n",
    "# Load the handwriting data (replace with your own data loading code)\n",
    "# Convert the lists to numpy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b12684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the images\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32') / 255.0\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Determine the number of unique labels in your dataset\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "y_train = to_categorical(y_train_encoded, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test_encoded, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3b2b173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 30s]\n",
      "val_accuracy: 0.5333333611488342\n",
      "\n",
      "Best val_accuracy So Far: 0.8777777552604675\n",
      "Total elapsed time: 00h 03m 18s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 10s 247ms/step - loss: 0.7323 - accuracy: 0.5458 - val_loss: 0.6890 - val_accuracy: 0.5222\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 5s 216ms/step - loss: 0.5684 - accuracy: 0.7347 - val_loss: 0.7127 - val_accuracy: 0.4778\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 3s 125ms/step - loss: 0.5196 - accuracy: 0.7347 - val_loss: 0.7026 - val_accuracy: 0.4778\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 3s 125ms/step - loss: 0.4450 - accuracy: 0.8028 - val_loss: 0.8126 - val_accuracy: 0.4778\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 3s 126ms/step - loss: 0.3927 - accuracy: 0.8319 - val_loss: 0.7029 - val_accuracy: 0.4778\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 3s 125ms/step - loss: 0.3486 - accuracy: 0.8569 - val_loss: 0.6845 - val_accuracy: 0.4778\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 3s 129ms/step - loss: 0.3176 - accuracy: 0.8722 - val_loss: 0.6823 - val_accuracy: 0.4778\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 3s 133ms/step - loss: 0.2691 - accuracy: 0.8917 - val_loss: 0.6213 - val_accuracy: 0.6056\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 3s 128ms/step - loss: 0.2308 - accuracy: 0.9097 - val_loss: 0.6277 - val_accuracy: 0.6667\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 3s 128ms/step - loss: 0.2008 - accuracy: 0.9292 - val_loss: 0.6008 - val_accuracy: 0.6111\n",
      "6/6 [==============================] - 1s 13ms/step - loss: 0.6008 - accuracy: 0.6111\n",
      "Loss: 0.6008375287055969\n",
      "Test accuracy: 0.6111111044883728\n"
     ]
    }
   ],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Convolutional layer\n",
    "    model.add(keras.layers.Conv2D(\n",
    "        filters=hp.Int('conv_filters', min_value=16, max_value=64, step=16),\n",
    "        kernel_size=(3, 3),\n",
    "        activation='relu',\n",
    "        input_shape=(28, 28, 1)\n",
    "    ))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Flatten the output from the convolutional layer\n",
    "    model.add(keras.layers.Flatten())\n",
    "    \n",
    "    # Dense hidden layer\n",
    "    model.add(keras.layers.Dense(\n",
    "        units=hp.Int('dense_units', min_value=64, max_value=256, step=64),\n",
    "        activation='relu'\n",
    "    ))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "    # Dense output layer\n",
    "    model.add(keras.layers.Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Perform hyperparameter search\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    directory='tuner_directory',\n",
    "    project_name='writer_identification'\n",
    ")\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "best_model = tuner.hypermodel.build(best_hp)\n",
    "\n",
    "# Train the best model\n",
    "best_model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the trained model\n",
    "best_model.save('writerIdentifier_model.h5')\n",
    "\n",
    "# Evaluate the best model\n",
    "loss, accuracy = best_model.evaluate(X_test, y_test)\n",
    "print('Loss:', loss)\n",
    "print('Test accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4b2a88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "{'conv_filters': 64, 'dense_units': 128}\n"
     ]
    }
   ],
   "source": [
    "print('Best Hyperparameters:')\n",
    "print(best_hp.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d931fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def resizeImage(image_number): \n",
    "\n",
    "    input_dir = 'Prediction-Test-Datasets'\n",
    "\n",
    "    output_dir = 'Resized-Prediction-Test-Datasets'\n",
    "    target_size = (28, 28)\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load the image\n",
    "    img_path = f\"{input_dir}/Predict-{image_number}.jpg\"\n",
    "    img = Image.open(img_path)\n",
    "        \n",
    "    # Resize the image while maintaining the aspect ratio using thumbnail method\n",
    "    img.thumbnail(target_size, Image.ANTIALIAS)\n",
    "        \n",
    "    # Create a new image with the target size as canvas\n",
    "    resized_image = Image.new('L', target_size, 255)\n",
    "        \n",
    "    # Paste the resized image onto the canvas\n",
    "    offset = ((target_size[0] - img.size[0]) // 2, (target_size[1] - img.size[1]) // 2)\n",
    "    resized_image.paste(img, offset)\n",
    "        \n",
    "    return resized_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb1c9959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Writer: Janice\n",
      "Confidence: 0.53548664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18192\\4217639828.py:19: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  img.thumbnail(target_size, Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('writerIdentifier_model.h5')\n",
    "\n",
    "# Preprocess the input image\n",
    "image_number = 4\n",
    "resized_image = resizeImage(image_number)\n",
    "input_image = np.array(resized_image)\n",
    "# Normalise\n",
    "input_image = input_image.reshape(1, 28, 28, 1).astype('float32') / 255.0\n",
    "\n",
    "# Convert the input image to a TensorFlow tensor\n",
    "input_tensor = tf.convert_to_tensor(input_image)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model(input_tensor)\n",
    "\n",
    "# Convert the predictions to a NumPy array\n",
    "predictions = predictions.numpy()\n",
    "\n",
    "\n",
    "# Get the writer with the highest probability\n",
    "predicted_writer_index = np.argmax(predictions)\n",
    "confidence = np.max(predictions)\n",
    "\n",
    "# Map the predicted index to the actual writer label\n",
    "# 1 - Janice; 2 - Jasmine\n",
    "writers = [1, 2]  # List of writer labels used during training\n",
    "predicted_writer = writers[predicted_writer_index]\n",
    "\n",
    "# Print the predicted writer and confidence score\n",
    "print('Predicted Writer:', \"Janice\" if predicted_writer == 1 else \"Jasmine\")\n",
    "print('Confidence:', confidence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
